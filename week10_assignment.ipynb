{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AURORARISE/MSSP-6070/blob/main/week10_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f2df115",
      "metadata": {
        "id": "6f2df115"
      },
      "source": [
        "# Week 9 â€“ Flickr Image Downloader (Improved)\n",
        "\n",
        "This notebook contains an improved version of the Flickr image downloader script.\n",
        "It is refactored for better readability, error handling, and easier reuse in a Jupyter environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80c50941",
      "metadata": {
        "id": "80c50941"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import List\n",
        "import requests\n",
        "\n",
        "USER_AGENT = (\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "    \"Chrome/120.0 Safari/537.36\"\n",
        ")\n",
        "\n",
        "def build_flickr_url(query: str) -> str:\n",
        "    \"\"\"Construct the URL of the Flickr public image feed based on the query keywords.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    query : str\n",
        "        Tags / keywords to search for.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        Fully formatted Flickr public feed URL.\n",
        "    \"\"\"\n",
        "    base_url = \"https://www.flickr.com/services/feeds/photos_public.gne\"\n",
        "    return f\"{base_url}?format=json&nojsoncallback=1&tags={query}\"\n",
        "\n",
        "def get_feed_json(url: str) -> dict:\n",
        "    \"\"\"Download the JSON of the Flickr feed.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    requests.HTTPError\n",
        "        If the request fails (non-2xx status).\n",
        "    \"\"\"\n",
        "    headers = {\"User-Agent\": USER_AGENT}\n",
        "    print(f\"[INFO] Fetching Flickr feed: {url}\")\n",
        "    res = requests.get(url, headers=headers, timeout=15)\n",
        "    res.raise_for_status()\n",
        "    return res.json()\n",
        "\n",
        "def extract_image_urls(feed_json: dict) -> List[str]:\n",
        "    \"\"\"Extract image URLs from Flickr's feed JSON.\n",
        "\n",
        "    Each item has a ``media`` field containing an ``m`` key, which is a\n",
        "    medium-sized image link.\n",
        "    \"\"\"\n",
        "    items = feed_json.get(\"items\", [])\n",
        "    image_urls: List[str] = []\n",
        "    for item in items:\n",
        "        media = item.get(\"media\", {})\n",
        "        img_url = media.get(\"m\")\n",
        "        if img_url:\n",
        "            image_urls.append(img_url)\n",
        "    return image_urls\n",
        "\n",
        "def download_image(url: str, folder: Path, index: int) -> Path | None:\n",
        "    \"\"\"Download a single image and save it to the specified folder.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    url : str\n",
        "        Image URL.\n",
        "    folder : Path\n",
        "        Output directory.\n",
        "    index : int\n",
        "        Fallback index used in filename if the URL has no basename.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"[INFO] Downloading image {index}: {url}\")\n",
        "        res = requests.get(url, timeout=20)\n",
        "        res.raise_for_status()\n",
        "\n",
        "        filename = Path(url.split(\"?\")[0]).name\n",
        "        if not filename:\n",
        "            filename = f\"image_{index}.jpg\"\n",
        "\n",
        "        folder.mkdir(parents=True, exist_ok=True)\n",
        "        file_path = folder / filename\n",
        "        file_path.write_bytes(res.content)\n",
        "\n",
        "        print(f\"[OK] Saved to {file_path}\")\n",
        "        return file_path\n",
        "    except Exception as e:  # noqa: BLE001\n",
        "        print(f\"[ERROR] Failed to download {url}: {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45124084",
      "metadata": {
        "id": "45124084"
      },
      "outputs": [],
      "source": [
        "def run_flickr_downloader(query: str, max_images: int | None = None, output_dir: str | None = None):\n",
        "    \"\"\"Run the Flickr downloader for a given query.\n",
        "\n",
        "    This function is notebook-friendly: instead of using ``input()``,\n",
        "    it takes ``query`` as an argument.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    query : str\n",
        "        Search term, e.g. \"cats\" or \"sunset\".\n",
        "    max_images : int, optional\n",
        "        If provided, limit the number of images to download.\n",
        "    output_dir : str, optional\n",
        "        Custom output directory. If omitted, a folder named\n",
        "        ``flickr_<query>`` will be created in the current directory.\n",
        "    \"\"\"\n",
        "    query = query.strip()\n",
        "    if not query:\n",
        "        raise ValueError(\"Query cannot be empty.\")\n",
        "\n",
        "    folder_name = output_dir or f\"flickr_{query.replace(' ', '_')}\"\n",
        "    folder = Path(folder_name)\n",
        "    print(f\"[INFO] Images will be saved to folder: {folder}\")\n",
        "\n",
        "    feed_url = build_flickr_url(query)\n",
        "    try:\n",
        "        feed_json = get_feed_json(feed_url)\n",
        "    except Exception as e:  # noqa: BLE001\n",
        "        print(f\"[ERROR] Failed to fetch Flickr feed: {e}\")\n",
        "        return []\n",
        "\n",
        "    image_urls = extract_image_urls(feed_json)\n",
        "    print(f\"[INFO] Found {len(image_urls)} image URLs in the feed.\")\n",
        "    if not image_urls:\n",
        "        print(\"No images found. Try another keyword.\")\n",
        "        return []\n",
        "\n",
        "    if max_images is not None:\n",
        "        image_urls = image_urls[:max_images]\n",
        "        print(f\"[INFO] Limiting download to {len(image_urls)} images.\")\n",
        "\n",
        "    saved_paths: list[Path] = []\n",
        "    for idx, img_url in enumerate(image_urls, start=1):\n",
        "        saved = download_image(img_url, folder, idx)\n",
        "        if saved is not None:\n",
        "            saved_paths.append(saved)\n",
        "\n",
        "    print(\"[DONE] All possible images have been processed.\")\n",
        "    return saved_paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcb0af98",
      "metadata": {
        "id": "dcb0af98"
      },
      "outputs": [],
      "source": [
        "# Example usage (uncomment and run in a real notebook environment):\n",
        "# downloaded_files = run_flickr_downloader(\"cats\", max_images=5)\n",
        "# downloaded_files"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}